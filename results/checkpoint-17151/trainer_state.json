{
  "best_global_step": 17151,
  "best_metric": 0.23774434626102448,
  "best_model_checkpoint": "./results\\checkpoint-17151",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 17151,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005830563815520961,
      "grad_norm": 1.8553004264831543,
      "learning_rate": 4.971138709113172e-05,
      "loss": 0.5988,
      "step": 100
    },
    {
      "epoch": 0.011661127631041922,
      "grad_norm": 8.485121726989746,
      "learning_rate": 4.9419858900355666e-05,
      "loss": 0.5142,
      "step": 200
    },
    {
      "epoch": 0.017491691446562884,
      "grad_norm": 4.826361179351807,
      "learning_rate": 4.9128330709579616e-05,
      "loss": 0.4504,
      "step": 300
    },
    {
      "epoch": 0.023322255262083844,
      "grad_norm": 5.266695022583008,
      "learning_rate": 4.883680251880357e-05,
      "loss": 0.406,
      "step": 400
    },
    {
      "epoch": 0.029152819077604804,
      "grad_norm": 3.175689697265625,
      "learning_rate": 4.854527432802752e-05,
      "loss": 0.3881,
      "step": 500
    },
    {
      "epoch": 0.03498338289312577,
      "grad_norm": 7.487310886383057,
      "learning_rate": 4.825374613725148e-05,
      "loss": 0.3678,
      "step": 600
    },
    {
      "epoch": 0.04081394670864673,
      "grad_norm": 6.829806327819824,
      "learning_rate": 4.796221794647542e-05,
      "loss": 0.3513,
      "step": 700
    },
    {
      "epoch": 0.04664451052416769,
      "grad_norm": 3.8304808139801025,
      "learning_rate": 4.767068975569938e-05,
      "loss": 0.3362,
      "step": 800
    },
    {
      "epoch": 0.05247507433968865,
      "grad_norm": 11.273577690124512,
      "learning_rate": 4.737916156492333e-05,
      "loss": 0.3444,
      "step": 900
    },
    {
      "epoch": 0.05830563815520961,
      "grad_norm": 11.318550109863281,
      "learning_rate": 4.7087633374147284e-05,
      "loss": 0.3317,
      "step": 1000
    },
    {
      "epoch": 0.06413620197073057,
      "grad_norm": 12.640735626220703,
      "learning_rate": 4.679610518337123e-05,
      "loss": 0.3472,
      "step": 1100
    },
    {
      "epoch": 0.06996676578625154,
      "grad_norm": 4.500720500946045,
      "learning_rate": 4.650457699259518e-05,
      "loss": 0.3195,
      "step": 1200
    },
    {
      "epoch": 0.07579732960177249,
      "grad_norm": 7.400755882263184,
      "learning_rate": 4.621304880181914e-05,
      "loss": 0.3191,
      "step": 1300
    },
    {
      "epoch": 0.08162789341729346,
      "grad_norm": 3.827437400817871,
      "learning_rate": 4.592152061104309e-05,
      "loss": 0.3366,
      "step": 1400
    },
    {
      "epoch": 0.08745845723281441,
      "grad_norm": 2.494659185409546,
      "learning_rate": 4.5629992420267045e-05,
      "loss": 0.3067,
      "step": 1500
    },
    {
      "epoch": 0.09328902104833538,
      "grad_norm": 5.574071884155273,
      "learning_rate": 4.5338464229490995e-05,
      "loss": 0.2924,
      "step": 1600
    },
    {
      "epoch": 0.09911958486385633,
      "grad_norm": 4.6802754402160645,
      "learning_rate": 4.504693603871495e-05,
      "loss": 0.3044,
      "step": 1700
    },
    {
      "epoch": 0.1049501486793773,
      "grad_norm": 24.891082763671875,
      "learning_rate": 4.4755407847938894e-05,
      "loss": 0.3019,
      "step": 1800
    },
    {
      "epoch": 0.11078071249489825,
      "grad_norm": 3.649662494659424,
      "learning_rate": 4.446387965716285e-05,
      "loss": 0.3084,
      "step": 1900
    },
    {
      "epoch": 0.11661127631041922,
      "grad_norm": 9.054375648498535,
      "learning_rate": 4.41723514663868e-05,
      "loss": 0.2875,
      "step": 2000
    },
    {
      "epoch": 0.12244184012594019,
      "grad_norm": 6.531296253204346,
      "learning_rate": 4.3880823275610756e-05,
      "loss": 0.3063,
      "step": 2100
    },
    {
      "epoch": 0.12827240394146114,
      "grad_norm": 8.082490921020508,
      "learning_rate": 4.3589295084834706e-05,
      "loss": 0.3075,
      "step": 2200
    },
    {
      "epoch": 0.1341029677569821,
      "grad_norm": 11.022289276123047,
      "learning_rate": 4.3297766894058656e-05,
      "loss": 0.3031,
      "step": 2300
    },
    {
      "epoch": 0.13993353157250307,
      "grad_norm": 3.0028481483459473,
      "learning_rate": 4.3006238703282605e-05,
      "loss": 0.3171,
      "step": 2400
    },
    {
      "epoch": 0.145764095388024,
      "grad_norm": 5.648118019104004,
      "learning_rate": 4.271471051250656e-05,
      "loss": 0.2873,
      "step": 2500
    },
    {
      "epoch": 0.15159465920354498,
      "grad_norm": 7.233090400695801,
      "learning_rate": 4.242318232173052e-05,
      "loss": 0.3087,
      "step": 2600
    },
    {
      "epoch": 0.15742522301906595,
      "grad_norm": 4.104413986206055,
      "learning_rate": 4.213165413095447e-05,
      "loss": 0.302,
      "step": 2700
    },
    {
      "epoch": 0.1632557868345869,
      "grad_norm": 13.676095962524414,
      "learning_rate": 4.184012594017842e-05,
      "loss": 0.2814,
      "step": 2800
    },
    {
      "epoch": 0.16908635065010785,
      "grad_norm": 12.767653465270996,
      "learning_rate": 4.154859774940237e-05,
      "loss": 0.261,
      "step": 2900
    },
    {
      "epoch": 0.17491691446562882,
      "grad_norm": 30.947141647338867,
      "learning_rate": 4.125706955862632e-05,
      "loss": 0.292,
      "step": 3000
    },
    {
      "epoch": 0.1807474782811498,
      "grad_norm": 6.411181449890137,
      "learning_rate": 4.096554136785027e-05,
      "loss": 0.2975,
      "step": 3100
    },
    {
      "epoch": 0.18657804209667075,
      "grad_norm": 8.1989107131958,
      "learning_rate": 4.067401317707423e-05,
      "loss": 0.2887,
      "step": 3200
    },
    {
      "epoch": 0.19240860591219172,
      "grad_norm": 5.4951558113098145,
      "learning_rate": 4.038248498629817e-05,
      "loss": 0.2815,
      "step": 3300
    },
    {
      "epoch": 0.19823916972771266,
      "grad_norm": 8.247466087341309,
      "learning_rate": 4.009095679552213e-05,
      "loss": 0.2958,
      "step": 3400
    },
    {
      "epoch": 0.20406973354323363,
      "grad_norm": 11.087747573852539,
      "learning_rate": 3.979942860474608e-05,
      "loss": 0.2711,
      "step": 3500
    },
    {
      "epoch": 0.2099002973587546,
      "grad_norm": 16.56717872619629,
      "learning_rate": 3.9507900413970035e-05,
      "loss": 0.2925,
      "step": 3600
    },
    {
      "epoch": 0.21573086117427556,
      "grad_norm": 6.860034942626953,
      "learning_rate": 3.9216372223193984e-05,
      "loss": 0.3034,
      "step": 3700
    },
    {
      "epoch": 0.2215614249897965,
      "grad_norm": 9.012619018554688,
      "learning_rate": 3.8924844032417934e-05,
      "loss": 0.26,
      "step": 3800
    },
    {
      "epoch": 0.22739198880531747,
      "grad_norm": 4.391763687133789,
      "learning_rate": 3.863331584164189e-05,
      "loss": 0.2944,
      "step": 3900
    },
    {
      "epoch": 0.23322255262083844,
      "grad_norm": 9.052197456359863,
      "learning_rate": 3.834178765086584e-05,
      "loss": 0.2656,
      "step": 4000
    },
    {
      "epoch": 0.2390531164363594,
      "grad_norm": 3.7800838947296143,
      "learning_rate": 3.8050259460089796e-05,
      "loss": 0.2753,
      "step": 4100
    },
    {
      "epoch": 0.24488368025188037,
      "grad_norm": 6.351420879364014,
      "learning_rate": 3.7758731269313746e-05,
      "loss": 0.2749,
      "step": 4200
    },
    {
      "epoch": 0.25071424406740134,
      "grad_norm": 10.19780158996582,
      "learning_rate": 3.7467203078537695e-05,
      "loss": 0.2801,
      "step": 4300
    },
    {
      "epoch": 0.2565448078829223,
      "grad_norm": 2.2633426189422607,
      "learning_rate": 3.7175674887761645e-05,
      "loss": 0.2531,
      "step": 4400
    },
    {
      "epoch": 0.2623753716984432,
      "grad_norm": 5.635679721832275,
      "learning_rate": 3.68841466969856e-05,
      "loss": 0.2933,
      "step": 4500
    },
    {
      "epoch": 0.2682059355139642,
      "grad_norm": 3.3909003734588623,
      "learning_rate": 3.659261850620955e-05,
      "loss": 0.2854,
      "step": 4600
    },
    {
      "epoch": 0.27403649932948515,
      "grad_norm": 11.955849647521973,
      "learning_rate": 3.630109031543351e-05,
      "loss": 0.2672,
      "step": 4700
    },
    {
      "epoch": 0.27986706314500615,
      "grad_norm": 10.387460708618164,
      "learning_rate": 3.600956212465746e-05,
      "loss": 0.2778,
      "step": 4800
    },
    {
      "epoch": 0.2856976269605271,
      "grad_norm": 26.9044246673584,
      "learning_rate": 3.5718033933881407e-05,
      "loss": 0.286,
      "step": 4900
    },
    {
      "epoch": 0.291528190776048,
      "grad_norm": 5.456349849700928,
      "learning_rate": 3.5426505743105356e-05,
      "loss": 0.2554,
      "step": 5000
    },
    {
      "epoch": 0.297358754591569,
      "grad_norm": 3.554677724838257,
      "learning_rate": 3.513497755232931e-05,
      "loss": 0.2618,
      "step": 5100
    },
    {
      "epoch": 0.30318931840708996,
      "grad_norm": 7.7737531661987305,
      "learning_rate": 3.484344936155326e-05,
      "loss": 0.2781,
      "step": 5200
    },
    {
      "epoch": 0.30901988222261095,
      "grad_norm": 8.276511192321777,
      "learning_rate": 3.455192117077722e-05,
      "loss": 0.2713,
      "step": 5300
    },
    {
      "epoch": 0.3148504460381319,
      "grad_norm": 5.886316299438477,
      "learning_rate": 3.426039298000117e-05,
      "loss": 0.266,
      "step": 5400
    },
    {
      "epoch": 0.32068100985365283,
      "grad_norm": 10.688899993896484,
      "learning_rate": 3.396886478922512e-05,
      "loss": 0.2676,
      "step": 5500
    },
    {
      "epoch": 0.3265115736691738,
      "grad_norm": 15.653650283813477,
      "learning_rate": 3.3677336598449074e-05,
      "loss": 0.2774,
      "step": 5600
    },
    {
      "epoch": 0.33234213748469477,
      "grad_norm": 16.74540138244629,
      "learning_rate": 3.3385808407673024e-05,
      "loss": 0.2981,
      "step": 5700
    },
    {
      "epoch": 0.3381727013002157,
      "grad_norm": 6.193833827972412,
      "learning_rate": 3.309428021689698e-05,
      "loss": 0.2816,
      "step": 5800
    },
    {
      "epoch": 0.3440032651157367,
      "grad_norm": 7.180574893951416,
      "learning_rate": 3.280275202612092e-05,
      "loss": 0.289,
      "step": 5900
    },
    {
      "epoch": 0.34983382893125764,
      "grad_norm": 3.7549262046813965,
      "learning_rate": 3.251122383534488e-05,
      "loss": 0.2625,
      "step": 6000
    },
    {
      "epoch": 0.35566439274677863,
      "grad_norm": 4.9177374839782715,
      "learning_rate": 3.221969564456883e-05,
      "loss": 0.275,
      "step": 6100
    },
    {
      "epoch": 0.3614949565622996,
      "grad_norm": 4.82704496383667,
      "learning_rate": 3.1928167453792785e-05,
      "loss": 0.2716,
      "step": 6200
    },
    {
      "epoch": 0.3673255203778205,
      "grad_norm": 4.7178053855896,
      "learning_rate": 3.1636639263016735e-05,
      "loss": 0.2634,
      "step": 6300
    },
    {
      "epoch": 0.3731560841933415,
      "grad_norm": 2.180716037750244,
      "learning_rate": 3.1345111072240685e-05,
      "loss": 0.2665,
      "step": 6400
    },
    {
      "epoch": 0.37898664800886245,
      "grad_norm": 11.98018741607666,
      "learning_rate": 3.105358288146464e-05,
      "loss": 0.271,
      "step": 6500
    },
    {
      "epoch": 0.38481721182438344,
      "grad_norm": 14.777397155761719,
      "learning_rate": 3.076205469068859e-05,
      "loss": 0.2712,
      "step": 6600
    },
    {
      "epoch": 0.3906477756399044,
      "grad_norm": 5.364429473876953,
      "learning_rate": 3.0470526499912544e-05,
      "loss": 0.2575,
      "step": 6700
    },
    {
      "epoch": 0.3964783394554253,
      "grad_norm": 6.044313907623291,
      "learning_rate": 3.0178998309136497e-05,
      "loss": 0.2923,
      "step": 6800
    },
    {
      "epoch": 0.4023089032709463,
      "grad_norm": 7.77932596206665,
      "learning_rate": 2.9887470118360443e-05,
      "loss": 0.2708,
      "step": 6900
    },
    {
      "epoch": 0.40813946708646726,
      "grad_norm": 7.349850177764893,
      "learning_rate": 2.9595941927584396e-05,
      "loss": 0.2593,
      "step": 7000
    },
    {
      "epoch": 0.4139700309019882,
      "grad_norm": 17.51035499572754,
      "learning_rate": 2.930441373680835e-05,
      "loss": 0.294,
      "step": 7100
    },
    {
      "epoch": 0.4198005947175092,
      "grad_norm": 2.618042230606079,
      "learning_rate": 2.9012885546032302e-05,
      "loss": 0.2755,
      "step": 7200
    },
    {
      "epoch": 0.42563115853303013,
      "grad_norm": 6.708308696746826,
      "learning_rate": 2.8721357355256255e-05,
      "loss": 0.2502,
      "step": 7300
    },
    {
      "epoch": 0.4314617223485511,
      "grad_norm": 4.994722366333008,
      "learning_rate": 2.8429829164480205e-05,
      "loss": 0.2564,
      "step": 7400
    },
    {
      "epoch": 0.43729228616407206,
      "grad_norm": 10.453636169433594,
      "learning_rate": 2.8138300973704158e-05,
      "loss": 0.2514,
      "step": 7500
    },
    {
      "epoch": 0.443122849979593,
      "grad_norm": 22.677400588989258,
      "learning_rate": 2.784677278292811e-05,
      "loss": 0.2488,
      "step": 7600
    },
    {
      "epoch": 0.448953413795114,
      "grad_norm": 6.869138717651367,
      "learning_rate": 2.7555244592152064e-05,
      "loss": 0.243,
      "step": 7700
    },
    {
      "epoch": 0.45478397761063494,
      "grad_norm": 4.360236644744873,
      "learning_rate": 2.7263716401376017e-05,
      "loss": 0.2455,
      "step": 7800
    },
    {
      "epoch": 0.46061454142615593,
      "grad_norm": 4.403964042663574,
      "learning_rate": 2.697218821059997e-05,
      "loss": 0.2672,
      "step": 7900
    },
    {
      "epoch": 0.46644510524167687,
      "grad_norm": 9.562187194824219,
      "learning_rate": 2.6680660019823916e-05,
      "loss": 0.2244,
      "step": 8000
    },
    {
      "epoch": 0.4722756690571978,
      "grad_norm": 3.916168689727783,
      "learning_rate": 2.638913182904787e-05,
      "loss": 0.2622,
      "step": 8100
    },
    {
      "epoch": 0.4781062328727188,
      "grad_norm": 3.133204221725464,
      "learning_rate": 2.6097603638271822e-05,
      "loss": 0.2742,
      "step": 8200
    },
    {
      "epoch": 0.48393679668823975,
      "grad_norm": 11.456219673156738,
      "learning_rate": 2.5806075447495775e-05,
      "loss": 0.248,
      "step": 8300
    },
    {
      "epoch": 0.48976736050376074,
      "grad_norm": 6.102144718170166,
      "learning_rate": 2.5514547256719728e-05,
      "loss": 0.259,
      "step": 8400
    },
    {
      "epoch": 0.4955979243192817,
      "grad_norm": 5.0393147468566895,
      "learning_rate": 2.5223019065943677e-05,
      "loss": 0.2602,
      "step": 8500
    },
    {
      "epoch": 0.5014284881348027,
      "grad_norm": 5.682592391967773,
      "learning_rate": 2.493149087516763e-05,
      "loss": 0.2375,
      "step": 8600
    },
    {
      "epoch": 0.5072590519503236,
      "grad_norm": 2.4183762073516846,
      "learning_rate": 2.4639962684391583e-05,
      "loss": 0.2561,
      "step": 8700
    },
    {
      "epoch": 0.5130896157658446,
      "grad_norm": 13.035748481750488,
      "learning_rate": 2.4348434493615536e-05,
      "loss": 0.2498,
      "step": 8800
    },
    {
      "epoch": 0.5189201795813655,
      "grad_norm": 24.51596450805664,
      "learning_rate": 2.4056906302839486e-05,
      "loss": 0.2654,
      "step": 8900
    },
    {
      "epoch": 0.5247507433968864,
      "grad_norm": 12.035265922546387,
      "learning_rate": 2.376537811206344e-05,
      "loss": 0.2534,
      "step": 9000
    },
    {
      "epoch": 0.5305813072124075,
      "grad_norm": 6.992096900939941,
      "learning_rate": 2.347384992128739e-05,
      "loss": 0.2475,
      "step": 9100
    },
    {
      "epoch": 0.5364118710279284,
      "grad_norm": 18.404766082763672,
      "learning_rate": 2.3182321730511342e-05,
      "loss": 0.2374,
      "step": 9200
    },
    {
      "epoch": 0.5422424348434494,
      "grad_norm": 8.659623146057129,
      "learning_rate": 2.2890793539735295e-05,
      "loss": 0.2855,
      "step": 9300
    },
    {
      "epoch": 0.5480729986589703,
      "grad_norm": 16.875545501708984,
      "learning_rate": 2.2599265348959244e-05,
      "loss": 0.2634,
      "step": 9400
    },
    {
      "epoch": 0.5539035624744912,
      "grad_norm": 5.210385799407959,
      "learning_rate": 2.2307737158183197e-05,
      "loss": 0.2443,
      "step": 9500
    },
    {
      "epoch": 0.5597341262900123,
      "grad_norm": 3.741676092147827,
      "learning_rate": 2.2016208967407147e-05,
      "loss": 0.2677,
      "step": 9600
    },
    {
      "epoch": 0.5655646901055332,
      "grad_norm": 5.779130458831787,
      "learning_rate": 2.17246807766311e-05,
      "loss": 0.2692,
      "step": 9700
    },
    {
      "epoch": 0.5713952539210542,
      "grad_norm": 5.39738130569458,
      "learning_rate": 2.1433152585855053e-05,
      "loss": 0.255,
      "step": 9800
    },
    {
      "epoch": 0.5772258177365751,
      "grad_norm": 3.0685036182403564,
      "learning_rate": 2.1141624395079006e-05,
      "loss": 0.2471,
      "step": 9900
    },
    {
      "epoch": 0.583056381552096,
      "grad_norm": 8.209588050842285,
      "learning_rate": 2.085009620430296e-05,
      "loss": 0.2591,
      "step": 10000
    },
    {
      "epoch": 0.5888869453676171,
      "grad_norm": 3.537374258041382,
      "learning_rate": 2.0558568013526912e-05,
      "loss": 0.2496,
      "step": 10100
    },
    {
      "epoch": 0.594717509183138,
      "grad_norm": 8.414984703063965,
      "learning_rate": 2.026703982275086e-05,
      "loss": 0.2319,
      "step": 10200
    },
    {
      "epoch": 0.600548072998659,
      "grad_norm": 7.137529373168945,
      "learning_rate": 1.9975511631974815e-05,
      "loss": 0.2784,
      "step": 10300
    },
    {
      "epoch": 0.6063786368141799,
      "grad_norm": 4.19963264465332,
      "learning_rate": 1.9683983441198764e-05,
      "loss": 0.2685,
      "step": 10400
    },
    {
      "epoch": 0.6122092006297009,
      "grad_norm": 12.237285614013672,
      "learning_rate": 1.9392455250422717e-05,
      "loss": 0.2527,
      "step": 10500
    },
    {
      "epoch": 0.6180397644452219,
      "grad_norm": 22.765146255493164,
      "learning_rate": 1.910092705964667e-05,
      "loss": 0.2516,
      "step": 10600
    },
    {
      "epoch": 0.6238703282607428,
      "grad_norm": 18.669755935668945,
      "learning_rate": 1.880939886887062e-05,
      "loss": 0.2514,
      "step": 10700
    },
    {
      "epoch": 0.6297008920762638,
      "grad_norm": 2.800215482711792,
      "learning_rate": 1.8517870678094573e-05,
      "loss": 0.2767,
      "step": 10800
    },
    {
      "epoch": 0.6355314558917847,
      "grad_norm": 9.785628318786621,
      "learning_rate": 1.8226342487318522e-05,
      "loss": 0.2615,
      "step": 10900
    },
    {
      "epoch": 0.6413620197073057,
      "grad_norm": 4.67824125289917,
      "learning_rate": 1.7934814296542475e-05,
      "loss": 0.237,
      "step": 11000
    },
    {
      "epoch": 0.6471925835228266,
      "grad_norm": 3.0973923206329346,
      "learning_rate": 1.764328610576643e-05,
      "loss": 0.2352,
      "step": 11100
    },
    {
      "epoch": 0.6530231473383477,
      "grad_norm": 6.689727306365967,
      "learning_rate": 1.7351757914990378e-05,
      "loss": 0.2345,
      "step": 11200
    },
    {
      "epoch": 0.6588537111538686,
      "grad_norm": 4.76552677154541,
      "learning_rate": 1.706022972421433e-05,
      "loss": 0.2661,
      "step": 11300
    },
    {
      "epoch": 0.6646842749693895,
      "grad_norm": 9.129945755004883,
      "learning_rate": 1.6768701533438284e-05,
      "loss": 0.2646,
      "step": 11400
    },
    {
      "epoch": 0.6705148387849105,
      "grad_norm": 7.488036155700684,
      "learning_rate": 1.6477173342662237e-05,
      "loss": 0.2599,
      "step": 11500
    },
    {
      "epoch": 0.6763454026004314,
      "grad_norm": 12.568161010742188,
      "learning_rate": 1.618564515188619e-05,
      "loss": 0.2426,
      "step": 11600
    },
    {
      "epoch": 0.6821759664159525,
      "grad_norm": 4.636572360992432,
      "learning_rate": 1.589411696111014e-05,
      "loss": 0.2503,
      "step": 11700
    },
    {
      "epoch": 0.6880065302314734,
      "grad_norm": 4.643167018890381,
      "learning_rate": 1.5602588770334093e-05,
      "loss": 0.2797,
      "step": 11800
    },
    {
      "epoch": 0.6938370940469943,
      "grad_norm": 6.938040733337402,
      "learning_rate": 1.5311060579558046e-05,
      "loss": 0.2656,
      "step": 11900
    },
    {
      "epoch": 0.6996676578625153,
      "grad_norm": 11.274663925170898,
      "learning_rate": 1.5019532388781995e-05,
      "loss": 0.2782,
      "step": 12000
    },
    {
      "epoch": 0.7054982216780362,
      "grad_norm": 2.1820313930511475,
      "learning_rate": 1.4728004198005948e-05,
      "loss": 0.2624,
      "step": 12100
    },
    {
      "epoch": 0.7113287854935573,
      "grad_norm": 17.57669448852539,
      "learning_rate": 1.4436476007229898e-05,
      "loss": 0.2702,
      "step": 12200
    },
    {
      "epoch": 0.7171593493090782,
      "grad_norm": 8.386236190795898,
      "learning_rate": 1.4144947816453853e-05,
      "loss": 0.2616,
      "step": 12300
    },
    {
      "epoch": 0.7229899131245991,
      "grad_norm": 4.681856632232666,
      "learning_rate": 1.3853419625677806e-05,
      "loss": 0.2615,
      "step": 12400
    },
    {
      "epoch": 0.7288204769401201,
      "grad_norm": 6.009687423706055,
      "learning_rate": 1.3561891434901755e-05,
      "loss": 0.2472,
      "step": 12500
    },
    {
      "epoch": 0.734651040755641,
      "grad_norm": 5.75816011428833,
      "learning_rate": 1.3270363244125708e-05,
      "loss": 0.2687,
      "step": 12600
    },
    {
      "epoch": 0.7404816045711621,
      "grad_norm": 5.584550857543945,
      "learning_rate": 1.2978835053349658e-05,
      "loss": 0.2445,
      "step": 12700
    },
    {
      "epoch": 0.746312168386683,
      "grad_norm": 11.395487785339355,
      "learning_rate": 1.2687306862573611e-05,
      "loss": 0.2718,
      "step": 12800
    },
    {
      "epoch": 0.752142732202204,
      "grad_norm": 14.908001899719238,
      "learning_rate": 1.2395778671797562e-05,
      "loss": 0.2563,
      "step": 12900
    },
    {
      "epoch": 0.7579732960177249,
      "grad_norm": 12.381821632385254,
      "learning_rate": 1.2104250481021515e-05,
      "loss": 0.2647,
      "step": 13000
    },
    {
      "epoch": 0.7638038598332458,
      "grad_norm": 12.323575973510742,
      "learning_rate": 1.1812722290245468e-05,
      "loss": 0.2534,
      "step": 13100
    },
    {
      "epoch": 0.7696344236487669,
      "grad_norm": 4.448244094848633,
      "learning_rate": 1.152119409946942e-05,
      "loss": 0.2356,
      "step": 13200
    },
    {
      "epoch": 0.7754649874642878,
      "grad_norm": 6.672256946563721,
      "learning_rate": 1.122966590869337e-05,
      "loss": 0.2532,
      "step": 13300
    },
    {
      "epoch": 0.7812955512798088,
      "grad_norm": 11.644159317016602,
      "learning_rate": 1.0938137717917322e-05,
      "loss": 0.251,
      "step": 13400
    },
    {
      "epoch": 0.7871261150953297,
      "grad_norm": 6.200319290161133,
      "learning_rate": 1.0646609527141275e-05,
      "loss": 0.2375,
      "step": 13500
    },
    {
      "epoch": 0.7929566789108506,
      "grad_norm": 6.133586883544922,
      "learning_rate": 1.0355081336365226e-05,
      "loss": 0.2382,
      "step": 13600
    },
    {
      "epoch": 0.7987872427263717,
      "grad_norm": 6.965369701385498,
      "learning_rate": 1.006355314558918e-05,
      "loss": 0.2392,
      "step": 13700
    },
    {
      "epoch": 0.8046178065418926,
      "grad_norm": 2.3782331943511963,
      "learning_rate": 9.77202495481313e-06,
      "loss": 0.2376,
      "step": 13800
    },
    {
      "epoch": 0.8104483703574136,
      "grad_norm": 12.695642471313477,
      "learning_rate": 9.480496764037084e-06,
      "loss": 0.2447,
      "step": 13900
    },
    {
      "epoch": 0.8162789341729345,
      "grad_norm": 8.191854476928711,
      "learning_rate": 9.188968573261035e-06,
      "loss": 0.2401,
      "step": 14000
    },
    {
      "epoch": 0.8221094979884555,
      "grad_norm": 11.443001747131348,
      "learning_rate": 8.897440382484986e-06,
      "loss": 0.2492,
      "step": 14100
    },
    {
      "epoch": 0.8279400618039764,
      "grad_norm": 8.712525367736816,
      "learning_rate": 8.605912191708938e-06,
      "loss": 0.2402,
      "step": 14200
    },
    {
      "epoch": 0.8337706256194974,
      "grad_norm": 11.470574378967285,
      "learning_rate": 8.31438400093289e-06,
      "loss": 0.2479,
      "step": 14300
    },
    {
      "epoch": 0.8396011894350184,
      "grad_norm": 25.08963394165039,
      "learning_rate": 8.022855810156844e-06,
      "loss": 0.2355,
      "step": 14400
    },
    {
      "epoch": 0.8454317532505393,
      "grad_norm": 4.965631008148193,
      "learning_rate": 7.731327619380795e-06,
      "loss": 0.2655,
      "step": 14500
    },
    {
      "epoch": 0.8512623170660603,
      "grad_norm": 20.150272369384766,
      "learning_rate": 7.439799428604746e-06,
      "loss": 0.2537,
      "step": 14600
    },
    {
      "epoch": 0.8570928808815812,
      "grad_norm": 5.569604873657227,
      "learning_rate": 7.148271237828698e-06,
      "loss": 0.2254,
      "step": 14700
    },
    {
      "epoch": 0.8629234446971022,
      "grad_norm": 14.751145362854004,
      "learning_rate": 6.856743047052651e-06,
      "loss": 0.2413,
      "step": 14800
    },
    {
      "epoch": 0.8687540085126232,
      "grad_norm": 7.518881797790527,
      "learning_rate": 6.565214856276603e-06,
      "loss": 0.2469,
      "step": 14900
    },
    {
      "epoch": 0.8745845723281441,
      "grad_norm": 11.630863189697266,
      "learning_rate": 6.273686665500554e-06,
      "loss": 0.2363,
      "step": 15000
    },
    {
      "epoch": 0.8804151361436651,
      "grad_norm": 13.072419166564941,
      "learning_rate": 5.982158474724506e-06,
      "loss": 0.2465,
      "step": 15100
    },
    {
      "epoch": 0.886245699959186,
      "grad_norm": 1.7610231637954712,
      "learning_rate": 5.690630283948458e-06,
      "loss": 0.2234,
      "step": 15200
    },
    {
      "epoch": 0.8920762637747071,
      "grad_norm": 4.93929386138916,
      "learning_rate": 5.39910209317241e-06,
      "loss": 0.2481,
      "step": 15300
    },
    {
      "epoch": 0.897906827590228,
      "grad_norm": 2.100084066390991,
      "learning_rate": 5.107573902396362e-06,
      "loss": 0.2552,
      "step": 15400
    },
    {
      "epoch": 0.9037373914057489,
      "grad_norm": 2.9757418632507324,
      "learning_rate": 4.816045711620314e-06,
      "loss": 0.243,
      "step": 15500
    },
    {
      "epoch": 0.9095679552212699,
      "grad_norm": 6.348333835601807,
      "learning_rate": 4.524517520844266e-06,
      "loss": 0.2293,
      "step": 15600
    },
    {
      "epoch": 0.9153985190367908,
      "grad_norm": 18.90215492248535,
      "learning_rate": 4.2329893300682175e-06,
      "loss": 0.2588,
      "step": 15700
    },
    {
      "epoch": 0.9212290828523119,
      "grad_norm": 17.642032623291016,
      "learning_rate": 3.94146113929217e-06,
      "loss": 0.2344,
      "step": 15800
    },
    {
      "epoch": 0.9270596466678328,
      "grad_norm": 5.94782829284668,
      "learning_rate": 3.6499329485161214e-06,
      "loss": 0.2386,
      "step": 15900
    },
    {
      "epoch": 0.9328902104833537,
      "grad_norm": 16.773971557617188,
      "learning_rate": 3.358404757740074e-06,
      "loss": 0.2612,
      "step": 16000
    },
    {
      "epoch": 0.9387207742988747,
      "grad_norm": 6.903848171234131,
      "learning_rate": 3.0668765669640257e-06,
      "loss": 0.2694,
      "step": 16100
    },
    {
      "epoch": 0.9445513381143956,
      "grad_norm": 14.435760498046875,
      "learning_rate": 2.7753483761879774e-06,
      "loss": 0.2536,
      "step": 16200
    },
    {
      "epoch": 0.9503819019299167,
      "grad_norm": 6.880395412445068,
      "learning_rate": 2.4838201854119296e-06,
      "loss": 0.2556,
      "step": 16300
    },
    {
      "epoch": 0.9562124657454376,
      "grad_norm": 4.490848541259766,
      "learning_rate": 2.1922919946358813e-06,
      "loss": 0.249,
      "step": 16400
    },
    {
      "epoch": 0.9620430295609586,
      "grad_norm": 8.52685832977295,
      "learning_rate": 1.9007638038598335e-06,
      "loss": 0.2539,
      "step": 16500
    },
    {
      "epoch": 0.9678735933764795,
      "grad_norm": 13.583184242248535,
      "learning_rate": 1.6092356130837854e-06,
      "loss": 0.2596,
      "step": 16600
    },
    {
      "epoch": 0.9737041571920004,
      "grad_norm": 4.510512828826904,
      "learning_rate": 1.3177074223077372e-06,
      "loss": 0.2415,
      "step": 16700
    },
    {
      "epoch": 0.9795347210075215,
      "grad_norm": 7.607034206390381,
      "learning_rate": 1.026179231531689e-06,
      "loss": 0.2738,
      "step": 16800
    },
    {
      "epoch": 0.9853652848230424,
      "grad_norm": 8.093080520629883,
      "learning_rate": 7.346510407556412e-07,
      "loss": 0.2381,
      "step": 16900
    },
    {
      "epoch": 0.9911958486385634,
      "grad_norm": 8.575397491455078,
      "learning_rate": 4.4312284997959305e-07,
      "loss": 0.2472,
      "step": 17000
    },
    {
      "epoch": 0.9970264124540843,
      "grad_norm": 7.452962398529053,
      "learning_rate": 1.51594659203545e-07,
      "loss": 0.2657,
      "step": 17100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.23774434626102448,
      "eval_runtime": 270.5155,
      "eval_samples_per_second": 253.608,
      "eval_steps_per_second": 3.963,
      "step": 17151
    }
  ],
  "logging_steps": 100,
  "max_steps": 17151,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 174320985784320.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
